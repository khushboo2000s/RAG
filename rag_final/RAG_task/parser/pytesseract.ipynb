{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 12:34:02,560 - INFO - Use pytorch device_name: cpu\n",
      "2024-10-04 12:34:02,561 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import PyPDF2\n",
    "import docx\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from openai import AzureOpenAI\n",
    "from config import Config  # Ensure config.py is accessible in the notebook's directory\n",
    "import re\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import io\n",
    "from search_utilities import create_search_index, upload_documents  # Ensure search_utilities.py is accessible\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the data folder path and chunk settings from the .env file\n",
    "data_folder_path = os.getenv('DATA_FOLDER_PATH')\n",
    "chunk_size = int(os.getenv('CHUNK_SIZE', 1000))  # Default chunk size is 1000 characters\n",
    "chunk_overlap = int(os.getenv('CHUNK_OVERLAP', 200))  # Default overlap is 200 characters\n",
    "\n",
    "config = Config()  # Ensure Config class is defined in config.py\n",
    "\n",
    "# Initialize Azure OpenAI client if in cloud approach\n",
    "if config.APPROACH == 'cloud':\n",
    "    client = AzureOpenAI(azure_endpoint=os.getenv(\"OPENAI_API_BASE\"),\n",
    "                         api_key='',  # Replace with your actual API key\n",
    "                         api_version='2024-02-15-preview')\n",
    "else:\n",
    "    # For on-premises, initialize the sentence transformer model\n",
    "    model_name = os.getenv('EMBEDDING_MODEL_NAME_ON_PREM', 'sentence-transformers/all-mpnet-base-v2')\n",
    "    model = SentenceTransformer(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read PDF Files:\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "\n",
    "                # Extract text\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text\n",
    "                else:\n",
    "                    logging.warning(f\"No text found on page {page_num} of {file_path}. Trying OCR.\")\n",
    "                    \n",
    "                    # If no text, attempt OCR for images\n",
    "                    images = page.images\n",
    "                    for image in images:\n",
    "                        try:\n",
    "                            pil_image = Image.open(io.BytesIO(image['data']))\n",
    "                            ocr_text = pytesseract.image_to_string(pil_image)\n",
    "                            logging.info(f\"OCR text extracted from image: {ocr_text}\")\n",
    "                            text += ocr_text\n",
    "                        except Exception as e:\n",
    "                            logging.error(f\"Error during OCR on page {page_num} of {file_path}: {e}\")\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading PDF file {file_path}: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ag_final\\RAG_task\\data_files\\ESGreport.pdf: [Errno 22] Invalid argument: 'D:\\\\Genai_project\\\\Retrieval Augmented Generation\\rag_final\\\\RAG_task\\\\data_files\\\\ESGreport.pdf'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_text = read_pdf(r'D:\\Genai_project\\Retrieval Augmented Generation\\rag_final\\RAG_task\\data_files\\ESGreport.pdf')\n",
    "print(pdf_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
